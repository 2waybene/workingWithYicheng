firstDT <- ""
get.gen <- ""
peaks   <- c()
dt.raw <- as.vector (dt$DNA_Index)
tol.num.of.dt <- length(dt.raw)
get.den <- density(dt.raw)
peaks <- peak.quick (get.den$x, get.den$y)
peaks
##==========================================================
##  Determine where to start the first population
##  There could be more small peaks less than 1
##  Try to get the first one peaks > 1 but < 1.2 (normMax)
##==========================================================
index = 1
length(which(peaks < 1))
if (!(is.na((peaks[length(which(peaks<1)) + 1]))) & peaks[length(which(peaks<1)) + 1] < normMax )
{
index = length(which(peaks<1)) + 1
}else { index = length(which(peaks<1)) }
index
##============================================
##  clean starts here with first population
##============================================
firstDT <- getPopWIndex (dt.raw, index)
##  Save first population dt
FP_dt_primary <- firstDT + peaks[index]
dt.cleaned <- cleanFirstPop(peaks[index], firstDT, dt.raw)
if (length(firstDT) >= length(dt.raw) & numOfFamily <=2)
{
SP_dt_primary <- dt.raw[c(which(dt.raw > normMax))]
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
}else{
##================================
##  Second round if ever needed
##================================
if (length (get.den <- tryDensity (dt.cleaned)) >=1 )
{
dt.raw  <- dt.cleaned
firstDT <- ""
get.gen <- ""
peaks   <- c()
index = 1
firstDT <- getPopWIndex (dt.raw, index) ##FIXME, yep breaks at sample 88!!!!
get.den <- density(dt.raw)
peaks <- peak.quick (get.den$x, get.den$y)
peaks
##=========================================
##  Follow the same protocol, but just
##  carry out one more cleaning cycle
##  if there is any peaks less than 1.2(normMax)
##===========================================
##Need to add the "cleaned back to population one"!!
dt.clean.return = list()
if (peaks[1] < normMax )
{
dt.clean.return <- followUpClean (peaks[1], firstDT, dt.raw)
if (length(dt.clean.return$dtFiltered) > 1) #FIXME, there was a bug
{
FP_dt_primary <- c(FP_dt_primary, dt.clean.return$dtFiltered)
}
dt.1pop.cleaned <- dt.clean.return$dtRetain
}else{
dt.1pop.cleaned <- dt.cleaned
}
##===================================
##  Storing the cleaning results
##===================================
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
} else
{
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
dt.1pop.cleaned <- dt.cleaned
}
}
##===========================================
##  No need to clean the second population
##===========================================
SP_mean  <- mean(SP_dt_primary)
SP_std   <- sd(SP_dt_primary)
SP_count <- length(SP_dt_primary)
SP <- list ("SP_mean" = SP_mean, "SP_std" = SP_std, "SP_count" = SP_count)
cleanedSample <- c(cleanedSample, SP)
aneup.pop <- ""
aneu <- list ("AneuLeft" = aneup.pop)
cleanedSample <- c(cleanedSample, aneu)
cleanedSample
##==========================
##  Saving the results
##==========================
storage.dir <- paste (root, "myGit/workingWithYicheng/phase-II-data/clearnedData/OLK/", sep = "")
file2save <- paste (storage.dir, "cleaned_", cleanedSample$sample, ".rda", sep="")
save (cleanedSample, file = file2save)
}
for (i in 1:length(rawFiles))
{
##  Get a random file index i
#i = floor(runif(1, min=1, length(rawFiles)))
fileName <- paste("myGit/workingWithYicheng/phase-II-data/OLK/", rawFiles[i], sep ="")
f_IN <-  paste (root, fileName, sep ="")
nameSplit <- strsplit(f_IN, "/")[[1]]
sampleName <- nameSplit[length(nameSplit)]
sampleName <- sub(".csv", "", sampleName)
sampleName
cleanedSample <-  list("sample" = sampleName)
cleanedSample
##============================
# read in the raw D.I. value
##============================
dt <- read.csv (f_IN)
## determine how many families are we dealing with
numOfFamily <-  1 # minimun one family
if (length(which(as.vector(dt$DNA_Index) > aneuThresh)) >= 1)
{
numOfFamily = 3
}else if (length(which(as.vector(dt$DNA_Index) > mitoThresh)) > 1)
{
numOfFamily = 2
}
numOfFamily
##===================================================
##  removing the normal family
##  upto two round
##===================================================
dt.raw  <- ""
firstDT <- ""
get.gen <- ""
peaks   <- c()
dt.raw <- as.vector (dt$DNA_Index)
tol.num.of.dt <- length(dt.raw)
get.den <- density(dt.raw)
peaks <- peak.quick (get.den$x, get.den$y)
peaks
##==========================================================
##  Determine where to start the first population
##  There could be more small peaks less than 1
##  Try to get the first one peaks > 1 but < 1.2 (normMax)
##==========================================================
index = 1
length(which(peaks < 1))
if (!(is.na((peaks[length(which(peaks<1)) + 1]))) & peaks[length(which(peaks<1)) + 1] < normMax )
{
index = length(which(peaks<1)) + 1
}else { index = length(which(peaks<1)) }
index
##============================================
##  clean starts here with first population
##============================================
firstDT <- getPopWIndex (dt.raw, index)
##  Save first population dt
FP_dt_primary <- firstDT + peaks[index]
dt.cleaned <- cleanFirstPop(peaks[index], firstDT, dt.raw)
if (length(firstDT) >= length(dt.raw) & numOfFamily <=2)
{
SP_dt_primary <- dt.raw[c(which(dt.raw > normMax))]
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
}else{
##================================
##  Second round if ever needed
##================================
if (length (get.den <- tryDensity (dt.cleaned)) >=1 )
{
dt.raw  <- dt.cleaned
firstDT <- ""
get.gen <- ""
peaks   <- c()
index = 1
firstDT <- getPopWIndex (dt.raw, index) ##FIXME, yep breaks at sample 88!!!!
get.den <- density(dt.raw)
peaks <- peak.quick (get.den$x, get.den$y)
peaks
##=========================================
##  Follow the same protocol, but just
##  carry out one more cleaning cycle
##  if there is any peaks less than 1.2(normMax)
##===========================================
##Need to add the "cleaned back to population one"!!
dt.clean.return = list()
if (peaks[1] < normMax )
{
dt.clean.return <- followUpClean (peaks[1], firstDT, dt.raw)
if (length(dt.clean.return$dtFiltered) > 1) #FIXME, there was a bug
{
FP_dt_primary <- c(FP_dt_primary, dt.clean.return$dtFiltered)
}
dt.1pop.cleaned <- dt.clean.return$dtRetain
}else{
dt.1pop.cleaned <- dt.cleaned
}
##===================================
##  Storing the cleaning results
##===================================
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
} else
{
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
dt.1pop.cleaned <- dt.cleaned
}
}
##===========================================
##  No need to clean the second population
##===========================================
SP_mean  <- mean(SP_dt_primary)
SP_std   <- sd(SP_dt_primary)
SP_count <- length(SP_dt_primary)
SP <- list ("SP_mean" = SP_mean, "SP_std" = SP_std, "SP_count" = SP_count)
cleanedSample <- c(cleanedSample, SP)
aneup.pop <- ""
aneu <- list ("AneuLeft" = aneup.pop)
cleanedSample <- c(cleanedSample, aneu)
cleanedSample
##==========================
##  Saving the results
##==========================
storage.dir <- paste (root, "myGit/workingWithYicheng/phase-II-data/clearnedData/OLK/", sep = "")
file2save <- paste (storage.dir, "cleaned_", cleanedSample$sample, ".rda", sep="")
save (cleanedSample, file = file2save)
}
## This is for phase II
dt.dir <- paste (root, "/myGit/workingWithYicheng/phase-II-data/clearnedData/OLK/", sep="")
lab <- "k"
files <- list.files (path = dt.dir, pattern=".rda")
reconed <- reconstruct(files, parameters)
olk.temp <- reconed[,-1]
dim(t(olk.temp))[1]
label <- rep(lab, dim(t(olk.temp))[1])
olk.out <- cbind(t(olk.temp), as.data.frame(label))
dim(olk.out)
setwd(paste (root, "/myGit/workingWithYicheng/phase-II-data/reconData/", sep="")) #Newly tested Feb 5th, 2016
getwd()
combined.recon <- rbind (oscc.out, olk.out)
rownames(combined.recon)
colnames(combined.recon)
write.table (combined.recon, "recon_3classes_para4.txt", sep="\t", col.names = NA)
##============================================
library(caret)
library(pROC)
library(Metrics)
root
require(compiler)
multiClassSummary <- cmpfun(function (data, lev = NULL, model = NULL)
{
#Load Libraries
require(Metrics)
require(caret)
#Check data
if (!all(levels(data[, "pred"]) == levels(data[, "obs"])))
stop("levels of observed and predicted data do not match")
#Calculate custom one-vs-all stats for each class
prob_stats <- lapply(levels(data[, "pred"]), function(class)
{
#Grab one-vs-all data for the class
pred <- ifelse(data[, "pred"] == class, 1, 0)
obs <- ifelse(data[, "obs"] == class, 1, 0)
prob <- data[,class]
#Calculate one-vs-all AUC and logLoss and return
cap_prob <- pmin(pmax(prob, .000001), .999999)
prob_stats <- c(auc(obs, prob), logLoss(obs, cap_prob))
names(prob_stats) <- c("ROC", "logLoss")
return(prob_stats)
})
prob_stats <- do.call(rbind, prob_stats)
rownames(prob_stats) <- paste( "Class:" , levels(data[, "pred"]))
#Calculate confusion matrix-based statistics
CM <- confusionMatrix(data[, "pred"], data[, "obs"])
#Aggregate and average class-wise stats
#Todo: add weights
class_stats <- cbind(CM$byClass, prob_stats)
class_stats <- colMeans(class_stats)
#Aggregate overall stats
overall_stats <- c(CM$overall)
#Combine overall with class-wise stats and remove some stats we don't want
stats <- c(overall_stats, class_stats)
stats <- stats[! names(stats) %in% c("AccuracyNull","Prevalence", "Detection Prevalence")]
#Clean names and return
names(stats) <- gsub('[[:blank:]] +', '_' , names(stats))
return(stats)
})
## Note: no visible binding for global variable 'Metrics'
## Note: no visible binding for global variable 'caret'
## set up working directory
setwd(paste (root, "/myGit/workingWithYicheng/phase-II-data/reconData/", sep=""))
data <- read.table("recon_3classes_para4.txt", header=TRUE, sep = "\t")
setwd(paste (root, "/myGit/workingWithYicheng/phase-II-data/modeling/", sep=""))
sink ("log_param4.txt")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##### BEGIN: data partition >>>>>
## set random seed
set.seed(12345)
## create data partition
inTrainingSet <- createDataPartition(data$label, p=.7, list=FALSE)
labelTrain <- dataN0[ inTrainingSet,]
labelTest <- dataN0[-inTrainingSet,]
#nrow(labelTrain)
#nrow(labelTest)
##### BEGIN: tune the parameters >>>>>
## control:
# resampling technique: 5-repeat 10-fold cross-validation
# performance metrics: ROC AUC curve
ctrl <- trainControl(method = "repeatedcv",
repeats = 5,
summaryFunction = multiClassSummary,
classProbs = TRUE)
##### END: tune the parameters <<<<<
##### BEGIN: train model - svm >>>>>
set.seed(1024)
svmFit <- train(label ~ ., data = labelTrain,
## training model: svm >>>
method = "svmRadial",
metric = "ROC",
tuneLength = 10,
trControl = ctrl)
## prediction
svmPred <- predict(svmFit, labelTest)
#str(svmPred)
## predicted probabilities
svmProbs <- predict(svmFit, labelTest, type = "prob")
#str(svmProbs)
cat ("This is the prediction with SVM")
cat("\n")
cat("\n")
confusionMatrix(svmPred, labelTest$label)
##### BEGIN: train model - random forest >>>>>
rfFit <- train(label ~ ., method = "rf", data = labelTrain)
rfPred <- predict(rfFit, labelTest)
cat("\n")
cat ("This is the prediction with random forest")
cat("\n")
cat("\n")
confusionMatrix(rfPred, labelTest$label)
##### BEGIN: train model - regularized random forest >>>>>
rrfFit <- train(label ~ ., method = "RRF", data = labelTrain)
rrfPred <- predict(rrfFit, labelTest)
cat("\n")
cat ("This is the prediction with regularized random forest")
cat("\n")
cat("\n")
confusionMatrix(rrfPred, labelTest$label)
##### BEGIN: train model - knn >>>>>
knnFit  <- train(
label ~ .,
data = labelTrain,
method='knn',
tuneGrid=expand.grid(.k=1:25),
metric='Accuracy',
trControl=trainControl(
method='repeatedcv',
number=10,
repeats=15))
knnPred <- predict(knnFit , labelTest)
cat("\n")
cat ("This is the prediction with k-nearest neighbor")
cat("\n")
cat("\n")
confusionMatrix(knnPred, labelTest$label)
##	Neural network
nnetFit <- train(
label ~ .,
data = labelTrain,
method = "nnet",
trace = FALSE,
maxit = 100)
nnetPred <- predict(nnetFit , labelTest)
cat("\n")
cat ("This is the prediction with neural network")
cat("\n")
confusionMatrix(nnetPred, labelTest$label)
##### BEGIN: train model - NaiveBayes >>>>>
nbFit  <- train(
label ~ .,
data = labelTrain,
method='nb',
trControl=trainControl(method='cv',number=10)
)
nbPred <- predict(nbFit , labelTest)
cat("\n")
cat ("This is the prediction with naive bayes")
cat("\n")
cat("\n")
confusionMatrix(nbPred, labelTest$label)
sink()
setwd(paste (root, "/myGit/workingWithYicheng/phase-I-data/reconData", sep=""))
data <- read.table("recon_3classes_para4.txt", header=TRUE, sep = "\t")
setwd(paste (root, "/myGit/workingWithYicheng/phase-II-data/modeling/", sep=""))
sink ("log_param4.txt")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##### BEGIN: data partition >>>>>
## set random seed
set.seed(12345)
## create data partition
inTrainingSet <- createDataPartition(data$label, p=.7, list=FALSE)
labelTrain <- dataN0[ inTrainingSet,]
labelTest <- dataN0[-inTrainingSet,]
#nrow(labelTrain)
#nrow(labelTest)
##### BEGIN: tune the parameters >>>>>
## control:
# resampling technique: 5-repeat 10-fold cross-validation
# performance metrics: ROC AUC curve
ctrl <- trainControl(method = "repeatedcv",
repeats = 5,
summaryFunction = multiClassSummary,
classProbs = TRUE)
##### END: tune the parameters <<<<<
##### BEGIN: train model - svm >>>>>
set.seed(1024)
svmFit <- train(label ~ ., data = labelTrain,
## training model: svm >>>
method = "svmRadial",
metric = "ROC",
tuneLength = 10,
trControl = ctrl)
## prediction
svmPred <- predict(svmFit, labelTest)
#str(svmPred)
## predicted probabilities
svmProbs <- predict(svmFit, labelTest, type = "prob")
#str(svmProbs)
cat ("This is the prediction with SVM")
cat("\n")
cat("\n")
confusionMatrix(svmPred, labelTest$label)
##### BEGIN: train model - random forest >>>>>
rfFit <- train(label ~ ., method = "rf", data = labelTrain)
rfPred <- predict(rfFit, labelTest)
cat("\n")
cat ("This is the prediction with random forest")
cat("\n")
cat("\n")
confusionMatrix(rfPred, labelTest$label)
##### BEGIN: train model - regularized random forest >>>>>
rrfFit <- train(label ~ ., method = "RRF", data = labelTrain)
rrfPred <- predict(rrfFit, labelTest)
cat("\n")
cat ("This is the prediction with regularized random forest")
cat("\n")
cat("\n")
confusionMatrix(rrfPred, labelTest$label)
##### BEGIN: train model - knn >>>>>
knnFit  <- train(
label ~ .,
data = labelTrain,
method='knn',
tuneGrid=expand.grid(.k=1:25),
metric='Accuracy',
trControl=trainControl(
method='repeatedcv',
number=10,
repeats=15))
knnPred <- predict(knnFit , labelTest)
cat("\n")
cat ("This is the prediction with k-nearest neighbor")
cat("\n")
cat("\n")
confusionMatrix(knnPred, labelTest$label)
##	Neural network
nnetFit <- train(
label ~ .,
data = labelTrain,
method = "nnet",
trace = FALSE,
maxit = 100)
nnetPred <- predict(nnetFit , labelTest)
cat("\n")
cat ("This is the prediction with neural network")
cat("\n")
confusionMatrix(nnetPred, labelTest$label)
##### BEGIN: train model - NaiveBayes >>>>>
nbFit  <- train(
label ~ .,
data = labelTrain,
method='nb',
trControl=trainControl(method='cv',number=10)
)
nbPred <- predict(nbFit , labelTest)
cat("\n")
cat ("This is the prediction with naive bayes")
cat("\n")
cat("\n")
confusionMatrix(nbPred, labelTest$label)
sink()
